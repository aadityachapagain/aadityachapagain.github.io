{"pageProps":{"post":{"slug":"wandb-your-machine-learning-project","title":"Wandb Your machine learning project.","date":"2020-09-02 12:00","modified":"2020-09-02 12:00","category":"Blog","summary":"Wandb Tool for visualizing and tracking your machine learning experiments better than tensorboard.","tags":"Datasets, Machine Learning, Visualization, training, Deep Learning, ML tools, tensorboard, python","authors":["Aaditya Chapagain"],"status":"published","content":"<p>Have you ever worked on large Machine learning projects or research where you have to manage many experimentations ? often during large projects or experiments you have to log every nits and bits of your Machine Learning training. Some of us might already be there.\nRecently I was also working on large Machine learning Projects and it was very hard for me to track every experiments logs, visualization, experiments. There were lots of them and It would take lots of time to prepare presentation's of my experiments results to my peers and that's when I learned about wandb.</p>\n<p>Wandb is API created by <a href=\"https://www.wandb.com/\">Weights &#x26; Biases</a> to collect, manage and visualize all your Machine learning experiments all at one place. Ohh, wait you must be wandering that <strong>tensorboard</strong> can also do these things right ?</p>\n<p>Well, there are lots of things which makes <strong>wandb</strong> a straight winner.</p>\n<ol>\n<li>Visually aesthetics UI.</li>\n<li>More manageable and customizable visualization and experiment tracking.</li>\n<li>Super easy to use API.</li>\n<li>Analyze system usage metrics alongside runs.</li>\n<li>Collaborate with team members</li>\n<li>Run parameter sweeps</li>\n<li>Keep records of experiments available forever</li>\n</ol>\n<p>I think the last point in above list is super cool, which is not feasible to do with tensorboard i.e You have to write huge amount of code by yourself to log these system wide metrics into tensorboard, but with wandb you can do this with just one line of code. and</p>\n<p>Lets Dive into wandb API.</p>\n<h1 id=\"installation\">Installation</h1>\n<p>Installing <code>wandb</code> is very easy, just run below command in terminal and you are good to go.</p>\n<pre><code class=\"hljs language-bash\">pip install wandb\n\npip install wandb --upgrade\n</code></pre>\n<p>One thing I noticed during installing wandb is that, if we run only <code>pip install wandb</code> it will sometimes only install wrapper class of wandb. So, upgrading wandb library after installing it , worked for me.</p>\n<h1 id=\"integration-with-your-python-code\">Integration with your python code</h1>\n<p>You can use <code>wandb</code> with any deeplearning framework, either it is pytorch or Tensorflow.But, first you need to have account on <a href=\"https://www.wandb.com/\">Weights &#x26; Biases</a>. After you create account on <a href=\"https://www.wandb.com/\">Weights &#x26; Biases</a> , you can get your wandb api keys from <a href=\"https://app.wandb.ai/settings\">setting</a>. After you get your keys, you just need to write couple of code to integrate your deeplearning system with wandb logger.</p>\n<h2 id=\"login\">Login</h2>\n<p>First you need to login into your wandb using wandb API KEYS. you can login programetically or from terminal, but login using terminal is advised.</p>\n<pre><code class=\"hljs language-bash\"><span class=\"hljs-comment\"># This is secret and shouldn't be checked into version control</span>\n<span class=\"hljs-built_in\">export</span> WANDB_API_KEY=<span class=\"hljs-variable\">$YOUR_API_KEY</span>\n\nwandb login\n</code></pre>\n<p>To Programatically login you can use following code:</p>\n<pre><code class=\"hljs language-python\">WANDB_API_KEYS = <span class=\"hljs-string\">\"&#x3C;your api keys here>\"</span>\n\n<span class=\"hljs-keyword\">import</span> wandb\n\nwandb.login(WANDB_API_KEYS) <span class=\"hljs-comment\"># if you don't have $WANDB_API_KEYS in your env variable (Not Advised)</span>\n\nwandb.login() <span class=\"hljs-comment\"># if $WANDB_API_KEYS is already been set.</span>\n</code></pre>\n<h2 id=\"initializing-wandb--wandbinit-\">Initializing wandb ( wandb.init )</h2>\n<p>Below you will see simple wandb integration examples with keras.</p>\n<pre><code class=\"hljs language-python\">\n<span class=\"hljs-comment\"># initialize wandb with your project name and optionally with configutations.</span>\nwandb.init(project=<span class=\"hljs-string\">'demo-keras-integration'</span>, name = <span class=\"hljs-string\">'first_run'</span>\n           config={\n              <span class=\"hljs-string\">\"learning_rate\"</span>: <span class=\"hljs-number\">0.005</span>,\n              <span class=\"hljs-string\">\"epochs\"</span>: <span class=\"hljs-number\">25</span>,\n              <span class=\"hljs-string\">\"batch_size\"</span>: <span class=\"hljs-number\">64</span>,\n              <span class=\"hljs-string\">\"loss_function\"</span>: <span class=\"hljs-string\">\"sparse_categorical_crossentropy\"</span>,\n              <span class=\"hljs-string\">\"architecture\"</span>: <span class=\"hljs-string\">\"CNN\"</span>,\n              <span class=\"hljs-string\">\"dataset\"</span>: <span class=\"hljs-string\">\"CIFAR-10\"</span>,\n           }, anonymous=<span class=\"hljs-string\">'never'</span>)\nconfig = wandb.config\n\n<span class=\"hljs-comment\"># Initialize model like you usually do.</span>\ntf.keras.backend.clear_session()\nmodel = Model()\nmodel.summary()\n\n<span class=\"hljs-comment\"># compile model like you usually do.</span>\n<span class=\"hljs-comment\"># notice use of config.</span>\noptimizer = tf.keras.optimizers.Adam(config.learning_rate)\nmodel.<span class=\"hljs-built_in\">compile</span>(optimizer, config.loss_function, metrics=[<span class=\"hljs-string\">'acc'</span>])\n\n</code></pre>\n<p><code>project</code> is name of your project and your project might have different run, so <code>name</code> parameter will distinguish one run from other.\nIf you run above code and get back to your wandb dashboard it will new project called <code>demo-keras-integration</code> and with <code>first_run</code> in it.</p>\n<p><a href=\"https://ibb.co/hDjwC6s\"><img src=\"/images/wandb-init.png\" alt=\"wandb Init\"></a></p>\n<p>Above init configuration will create new run everytime you call <code>wandb.init</code> But sometimes that not what you want, If your training is preemptible and might takes days or months to complete then you can resume from previous logged metrics by providing <code>resume = True</code> parameter to <code>wandb.init</code> and you will also need to set unique id, to distinguish one run from another. Below code will resume your logs with current run in your wandb dashboard even after you run <code>init</code> multiple times.</p>\n<pre><code class=\"hljs language-python\">\nwandb.init(project=<span class=\"hljs-string\">'demo-keras-integration'</span>, name = <span class=\"hljs-string\">'first_run'</span>, resume= <span class=\"hljs-literal\">True</span>,\n            <span class=\"hljs-built_in\">id</span> = <span class=\"hljs-string\">'my_first_run'</span>\n           config={\n              <span class=\"hljs-string\">\"learning_rate\"</span>: <span class=\"hljs-number\">0.005</span>,\n              <span class=\"hljs-string\">\"epochs\"</span>: <span class=\"hljs-number\">25</span>,\n              <span class=\"hljs-string\">\"batch_size\"</span>: <span class=\"hljs-number\">64</span>,\n              <span class=\"hljs-string\">\"loss_function\"</span>: <span class=\"hljs-string\">\"sparse_categorical_crossentropy\"</span>,\n              <span class=\"hljs-string\">\"architecture\"</span>: <span class=\"hljs-string\">\"CNN\"</span>,\n              <span class=\"hljs-string\">\"dataset\"</span>: <span class=\"hljs-string\">\"CIFAR-10\"</span>,\n           }, anonymous=<span class=\"hljs-string\">'never'</span>)\n</code></pre>\n<h2 id=\"train-with-wandb-callback\">Train with Wandb callback</h2>\n<p>wandb made easy to log your model metrics into your project space by providing various callback function to log your metrics directly into wandb dashboard, without writing extra code.</p>\n<pre><code class=\"hljs language-python\">\n<span class=\"hljs-keyword\">from</span> wandb.keras <span class=\"hljs-keyword\">import</span> WandbCallback\n\n<span class=\"hljs-comment\"># train with our favorite model.fit</span>\n<span class=\"hljs-comment\"># notice WandbCallback used as a regular callback</span>\n<span class=\"hljs-comment\"># notice the use of config</span>\n_ = model.fit(x_train, y_train,\n          epochs=config.epochs,\n          batch_size=config.batch_size,\n          validation_data=(x_test, y_test),\n          callbacks=[WandbCallback()])\n\n</code></pre>\n<p>If you are working on images and need a way to log your correctly classified and misclassified sample images, you can also do so using wandb. Below you will see the examples of it.</p>\n<pre><code class=\"hljs language-python\">\n<span class=\"hljs-comment\"># in order to get prediction on small subset of images.</span>\nval_images, val_labels = x_test[:<span class=\"hljs-number\">32</span>], y_test[:<span class=\"hljs-number\">32</span>]\n\n<span class=\"hljs-comment\"># train with our favorite model.fit</span>\n<span class=\"hljs-comment\"># notice WandbCallback used as a regular callback</span>\n<span class=\"hljs-comment\"># notice that we are passing in some arguments as well</span>\n<span class=\"hljs-comment\"># notice the use of config</span>\n_ = model.fit(x_train, y_train,\n          epochs=config.epochs,\n          batch_size=config.batch_size,\n          validation_data=(x_test, y_test),\n          callbacks=[WandbCallback(data_type=<span class=\"hljs-string\">'image'</span>,\n                                   training_data=(val_images, val_labels),\n                                   labels=CLASS_NAMES)])\n</code></pre>\n<p><a href=\"https://ibb.co/ZcbvNP9\"><img src=\"/images/wand-log-images.png\" alt=\"logging images with wandb\"></a></p>\n<h2 id=\"log-custom-metrics-with-wandblog\">Log Custom metrics with wandb.log</h2>\n<p>You can always log custom metrics and extra information using wandb.log .</p>\n<pre><code class=\"hljs language-python\">loss, accuracy = model.evaluate(x_test, y_test)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">'Test Error Rate: '</span>, <span class=\"hljs-built_in\">round</span>((<span class=\"hljs-number\">1</span>-accuracy)*<span class=\"hljs-number\">100</span>, <span class=\"hljs-number\">2</span>))\n\n<span class=\"hljs-comment\"># notice the use of wandb.log.</span>\n<span class=\"hljs-comment\"># We can easiy pass in values as key-value pairs.</span>\nwandb.log({<span class=\"hljs-string\">'Test Error Rate'</span>: <span class=\"hljs-built_in\">round</span>((<span class=\"hljs-number\">1</span>-accuracy)*<span class=\"hljs-number\">100</span>, <span class=\"hljs-number\">2</span>)})\n\n</code></pre>\n<h1 id=\"wandb-dashboard\">wandb Dashboard</h1>\n<p><a href=\"https://ibb.co/tBZDJzW\"><img src=\"/images/wandb-dashboard.png\" alt=\"Wandb dashboard\"></a></p>\n<p>You can see all your logged metrics in your wandb project dashboard. Wandb Groups information into different sections like Overview, Charts ,logs, system, model and files.</p>\n<h2 id=\"overview\">Overview</h2>\n<p><a href=\"https://ibb.co/RvNFHTW\"><img src=\"/images/wandb-overview.png\" alt=\"Wandb dashboard\"></a></p>\n<p>The information in the <code>overview</code> section is pretty intuitive and self-explanatory. However, the Git Repository field and the Git State field are worthy of special mention. You can run the checkout command in the Git State field to pin down the exact code for reproducing the experiment. Under the hood, wandb tracks all the changes you made to the original repo, and save the \"diff\" files in a local directory. In this way, you can easily switch between different versions of the code without manually pushing the change to the remote repo.</p>\n<h2 id=\"logs\">Logs</h2>\n<p>The <code>logs</code> section shows the console output during the experiment. This is useful for debugging the performance of the model.</p>\n<p><a href=\"https://ibb.co/hmKFC7H\"><img src=\"/images/wandb-logs.png\" alt=\"Wandb dashboard\"></a></p>\n<h2 id=\"systems\">Systems</h2>\n<p>To me, the system section is where wandb really shines and separates itself from other options such as TensorBoard. It is a centralized place to track system utilization during the experiment. There are in total of 8 graphs displayed in this section. These graphs give you insight into the training bottleneck and possible ways to uplift it. For example, below are the diagrams of the experiment:</p>\n<p><a href=\"https://ibb.co/VNGQbyQ\"><img src=\"/images/wandb-system.png\" alt=\"Wandb dashboard\"></a></p>\n<h2 id=\"tensorboard\">Tensorboard</h2>\n<p>wandb also provide options for people who love tensorboard. You can directly sync wandb with tensorboard by just setting <code>sync_tensorboard = True</code> in your <code>wandb.init</code>. So, that every information that is logged into tensorboard will also be logged into wandb.</p>\n<pre><code class=\"hljs language-python\">\nwandb.init(\n    name = <span class=\"hljs-string\">'&#x3C;your run name>'</span>,\n    project = <span class=\"hljs-string\">'your project name'</span>,\n    config = <span class=\"hljs-string\">'&#x3C;your config>'</span>,\n    sync_tensorboard = <span class=\"hljs-literal\">True</span>)\n</code></pre>\n<h1 id=\"summary\">Summary</h1>\n<p>We discuss how to integrate wandb in any deeplearning framework using python for inspecting the efficiency of training jobs. We also looked into other aspects of wandb that makes it so much unique than other training logging software like tensorboard.</p>\n<p>To learn more about wandb, check out their website: <a href=\"https://www.wandb.com/\">https://www.wandb.com/</a>.</p>"}},"__N_SSG":true}